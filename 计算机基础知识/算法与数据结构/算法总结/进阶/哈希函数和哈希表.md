# 认识哈希函数和哈希表

**关于哈希函数的几条性质**

1. 输入域是无穷的 输出域是有限的
2. 相同的输入，相同的输出
3. 不同的输入，相同的输出 （哈希碰撞） 
4. 在数据规模较大的情况下，具有离散性和均匀性
5. 输入即使有规律，输出照样是无序的
6. 当经过哈希函数算出来的值经过 `%m` 运算，那么结果会在 `[0 - m-1]` 上均匀分布

**一道相关例题**

有一个文件，里面有40亿的无符号整数，最多给你1G内存，求一个数出现的最大次数

最坏情况下使用哈希表大约需要 32G 的空间

因为在最坏的情况下不同的数字太多了，占用内存

**怎么做**

将大文件分成小文件挨个计算

1. 将所有的数字都丢到哈希函数算一遍
2. 将算出来的哈希函数取余运算，将对应的数放到对应的文件
3. 对分出来的小文件，用哈希表遍历，得到这个文件的最多出现的数字
4. 然后比较即可

**哈希表的具体实现**

1. 开放寻址法

	一个大数组，当出现哈希冲突，向下寻址将这个元素放在没有占用的位置

2. 链地址法

	当出现地哈希冲突，在当前地址向下延伸节点，当节点过长时将链表转化为**红黑树**，除非数据规模过大才扩容

	而且Java这种运行在虚拟机的语言，还可以**离线扩容**，在比较空闲的时候，在后台实现扩容 

**哈希表具体代码**

```java
package class01;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map.Entry;

public class Code01_HashMap {

    public static void main(String[] args) {
        HashMap<String, String> map = new HashMap<>();
        map.put("zuo", "31");

        System.out.println(map.containsKey("zuo"));
        System.out.println(map.containsKey("chengyun"));
        System.out.println("=========================");

        System.out.println(map.get("zuo"));
        System.out.println(map.get("chengyun"));
        System.out.println("=========================");

        System.out.println(map.isEmpty());
        System.out.println(map.size());
        System.out.println("=========================");

        System.out.println(map.remove("zuo"));
        System.out.println(map.containsKey("zuo"));
        System.out.println(map.get("zuo"));
        System.out.println(map.isEmpty());
        System.out.println(map.size());
        System.out.println("=========================");

        map.put("zuo", "31");
        System.out.println(map.get("zuo"));
        map.put("zuo", "32");
        System.out.println(map.get("zuo"));
        System.out.println("=========================");

        map.put("zuo", "31");
        map.put("cheng", "32");
        map.put("yun", "33");

        for (String key : map.keySet()) {
            System.out.println(key);
        }
        System.out.println("=========================");

        for (String values : map.values()) {
            System.out.println(values);
        }
        System.out.println("=========================");

        map.clear();
        map.put("A", "1");
        map.put("B", "2");
        map.put("C", "3");
        map.put("D", "1");
        map.put("E", "2");
        map.put("F", "3");
        map.put("G", "1");
        map.put("H", "2");
        map.put("I", "3");
        for (Entry<String, String> entry : map.entrySet()) {
            String key = entry.getKey();
            String value = entry.getValue();
            System.out.println(key + "," + value);
        }
        System.out.println("=========================");

        // you can not remove item in map when you use the iterator of map
		  //		 for(Entry<String,String> entry : map.entrySet()){
		  //			 if(!entry.getValue().equals("1")){
		  //				 map.remove(entry.getKey());
		  //			 }
		  //		 }
        // if you want to remove items, collect them first, then remove them by
        // this way.
        List<String> removeKeys = new ArrayList<String>();
        for (Entry<String, String> entry : map.entrySet()) {
            if (!entry.getValue().equals("1")) {
                removeKeys.add(entry.getKey());
            }
        }
        for (String removeKey : removeKeys) {
            map.remove(removeKey);
        }
        for (Entry<String, String> entry : map.entrySet()) {
            String key = entry.getKey();
            String value = entry.getValue();
            System.out.println(key + "," + value);
        }
        System.out.println("=========================");

    }

}

```

# 设计RandomPool结构

 **题目**

**设计一种结构，在该结构中有如下三个功能**

`insert(key)`  将某个key加入到该结构，做到不重复加入

`delete(key)`  将原本在结构中的某个key移除

`getRandom()`  等概率随机返回结构中的任何一个key

**要求**

`Insert`、`delete` 和  `getRandom` 方法的时间复杂度都是 $O(1)$

**如何实现**

准备两张哈希表，构成双射，每一个字母对应着一个递增的整数，通过随机函数乘以 `size` 来生成对应的整数

`insert(key)`  将数字填入哈希表，每次填入 `size` 这个信息 

`delete(key)`  将对应的字母删除，并将当前最后一个元素填入到当前被删除的位置，更新信息，维护 `size`

`getRandom()`  将随机函数生成的浮点数乘以 `size` 并强制转化为 `int` 类型，取出对应的东西

**代码实现**

```java
package class01;

import java.util.HashMap;

public class Code02_RandomPool {

    public static class Pool<K> {
        private HashMap<K, Integer> keyIndexMap;
        private HashMap<Integer, K> indexKeyMap;
        private int size;

        public Pool() {
            this.keyIndexMap = new HashMap<K, Integer>();
            this.indexKeyMap = new HashMap<Integer, K>();
            this.size = 0;
        }

        public void insert(K key) {
            if (!this.keyIndexMap.containsKey(key)) {
                this.keyIndexMap.put(key, this.size);
                this.indexKeyMap.put(this.size++, key);
            }
        }

        public void delete(K key) {
            if (this.keyIndexMap.containsKey(key)) {
                int deleteIndex = this.keyIndexMap.get(key);
                int lastIndex = --this.size;
                K lastKey = this.indexKeyMap.get(lastIndex);
                this.keyIndexMap.put(lastKey, deleteIndex);
                this.indexKeyMap.put(deleteIndex, lastKey);
                this.keyIndexMap.remove(key);
                this.indexKeyMap.remove(lastIndex);
            }
        }

        public K getRandom() {
            if (this.size == 0) {
                return null;
            }
            int randomIndex = (int) (Math.random() * this.size); // 0 ~ size -1
            return this.indexKeyMap.get(randomIndex);
        }

    }

    public static void main(String[] args) {
        Pool<String> pool = new Pool<String>();
        pool.insert("zuo");
        pool.insert("cheng");
        pool.insert("yun");
        System.out.println(pool.getRandom());
        System.out.println(pool.getRandom());
        System.out.println(pool.getRandom());
        System.out.println(pool.getRandom());
        System.out.println(pool.getRandom());
        System.out.println(pool.getRandom());

    }

}

```

# 认识布隆过滤器

**是做什么的**

面对一个庞大数据量的系统，如何设计才能使得这个识别系统，使得它不那么占用空间，而且不需要删除，只需要添加

经典用途

- 黑名单系统
- 爬虫去重问题

**相关举例**

假设有个黑名单有1000亿个URL，现在需要你自己去实现黑名单系统，但是只能使用最多30GB的内存，而且允许有容错率，这个时候就可以使用布隆过滤器。

而且布隆过滤器的发生错误的时候，是宁可错杀绝不放过一个的类型，但是可以通过人为的设计使得错误率极低

**前提知识**

**位图**

`bit array / bit map`

我们都见过基础类型的数组

```java
int [] //每一个盒子四个字节 -> 32bit
long [] //每个盒子八个字节 -> 64bit
bit[] //每个盒子一个比特
```

但是怎么做出比特类型的数组呢 ？

用基础数组拼

布隆过滤器就是一个大位图

**相关代码**

```java
package class01;

public class Code05_BitMap {
    public static void main(String[] args) {
        int a = 0;
        //  a -> 32 bit

        int[] arr = new int[10];
        // 32 bit * 10 -> 320 bit
        /*
        arr[0] int  0 ～ 31
        arr[1] int  32 ～ 63
        arr[2] int  64 ～ 95
         */

        //想取得第178位 bit 的状态
        int i = 178;

        int numIndex = i / 32;
        //拿到对应的数字下表 也就是bit的区间段
        int bitIndex = i % 32;
        //在这一个区间我需要找那一位的比特

        //拿到第 i 位置的状态
        int s = ((arr[numIndex] >> (bitIndex)) & 1);

        //修改第 i 位置的 bit 信息为 1
        arr[numIndex] = arr[numIndex] | (1 << (bitIndex));

        //修改第 i 位置的 bit 信息为 0
        arr[numIndex] = arr[numIndex] & (~(1 << bitIndex));

        //拿到第 i 位置的状态
        int bit = ((arr[i / 32] >> (i % 32)) & 1);
    }
}

```

**如何实现布隆过滤器**

首先申请一个足够大的数组，看作 bit 数组

1. 将一个输入通过 k 个哈希函数的计算得到 k 个哈希值并取模运算，将这些位置的比特位设置为 1
2. 将所有的数据都带入计算，得到了一个数组，这个就是过滤器的规则
3. 如果一个数据带入计算发现数组的某一个位置没有被标记，则这个不是在过滤器中的数据，放行 

**相关公式**

${\Huge {\huge m = - \frac{n \times \ln_{}{p} }{(\ln_{}{2})^2} } } $​​

${\Huge k = \ln_{}{2}\times \frac{m}{n}  } {\Huge } $​

${\Huge R = 1- e^{- \frac{n \times k}{m}{} } } $​

$k$ 不同的哈希函数的个数

$m$ 所需比特位

$n$ 实际样本数

$p$ 预估错误概率

$R$ 真实失误率

# 详解一致性哈希原理

**后端必考**

这个是讨论数据服务器是如何组织的一个问题

**举个例子**

比如现在的分布式数据库，如何让用户查到自己想要的数据，就用到了哈希函数，来分配对应的数据库服务器

但是需要数据有一定的规模，像是身份证号，人名

而不能是国家或者性别这些，这种数据量很少的

但是经典结构下，增加一台新的数据服务器需要重新计算哈希值，这样会导致每增加或者减去服务器时数据迁移的代价过大

而且如果之后接手大项目或者是使用分布式数据库，肯定要精通数据库原理和这些一致性理论

那么现在就引出了一个问题

**咋样才能使得数据库迁移成本降低**

这个时候就是牵扯到一致性哈希的使用了

假设使用 MD5 这个哈希函数它的范围为 $[0 ～ 2^{64}-1]$

将这一个范围首尾顺时针相连形成一个环

假设我现在有三台机器

`m1 m2 m3`

将着三台机器用某个指标放入哈希函数计算得到一个数值，然后根据数值来进行划分区域

并将划分好的区域按数值大小放在逻辑端服务器上

在查询的时候使用二分查找在顺时针查找对应的数据服务器

到现在添加服务器和减去服务器数据迁移量肉眼可见的减少

添加服务器时，找出新加入的服务器占用了那一段区间

就把这一段的区间的数据迁移到新的服务器

删除同理

**但是新的问题出现了**

当机器数量过少的时候，这个区间得不到均分

所以当前的问题就是在服务器较少的情况下如何将这个大区间均分

即使当先均分了，当加入一台新的机器，区间又变得不均分了

解决掉这个问题一致性哈希就非常好用了

**采用虚拟节点技术**

那我们就扩大数据规模，这样就能做到区间均分了

让每台服务器都维护一定数量不同的样本，将算出来的哈希值插在点上

这样就完成了圆环的均分

即使添加和删除也十分的方便

只要相应的数据在逻辑服务器，通过二分搜索，查询速度依旧很快

**而且这项技术可以动态调整负载**

假如一台机器性能超强，我们可以划分相对多的节点

假如一台机器性能较弱，我们可以划分相对少的节点
