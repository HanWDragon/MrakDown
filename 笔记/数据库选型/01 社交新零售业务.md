# 导学

## 业务场景发展与流程定义

### 传统电商

![](image/Pasted%20image%2020241207235501.png)

### 新零售

- 线上 + 线下

![](image/Pasted%20image%2020241207235541.png)


## 业务流程

### 新零售业务流程

![](image/Pasted%20image%2020241207235722.png)

### 社交零售流程

![](image/Pasted%20image%2020241207235913.png)

## 技术架构全景

- 不要先写代码，先完成技术架构设计

![](image/Pasted%20image%2020241208000105.png)

### 模块拆分

![](image/Pasted%20image%2020241208000134.png)

## 存储选型

### 关系型数据库

![](image/Pasted%20image%2020241208000834.png)

### 非关系型数据库

![](image/Pasted%20image%2020241208000905.png)

## 前置环节搭建

### Docker 和 Mysql

#### Docker 基本能力

![](image/Pasted%20image%2020241208001533.png)

```shell
docker -itd --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:latest
docker exec -it mysql bash
mysql -u -p123456 
alter user 'root'@'%' identified with mysql_native_password by '123456';
flush privileges;
```
### SpringBoot搭建

### Mybatis Plus 接入

![](image/Pasted%20image%2020241208003755.png)

![](image/Pasted%20image%2020241208010522.png)

# Mysql

## 优势

![](image/Pasted%20image%2020241208015851.png)

## 劣势

![](image/Pasted%20image%2020241208015922.png)

## 存储引擎

![](image/Pasted%20image%2020241208020046.png)

## 事务支持

- 脏读，事务未提交就可以查到
- 不可重复读，同一条记录，通过事务修改数据后，读取的数据不一样
- 幻读，一个查询在不同时间产生不同结果集

![](image/Pasted%20image%2020241208020113.png)

## 快照读和当前读

![](image/Pasted%20image%2020241208022541.png)

![](image/Pasted%20image%2020241208023227.png)

- 行锁还是表锁，是看这个语句是否通过索引来查找，如果 username 没有索引还是表锁
- 不推荐对非唯一索引使用 for update，会造成间隙锁，一个区间都上锁

## 索引

- 尽可能使用聚簇索引查询，即使是唯一非聚簇索引查询速度也比聚簇索引满一个数量级

![](image/Pasted%20image%2020241208024117.png)


### 优化

#### 全值匹配

- 查询条件最好索引全覆盖
- 经常排序也可以建索引

#### 最左原则

- 索引都放在左边，索引建 a，b，条件查 b，a 无法命中索引
- 但是最新有优化
- 慎用 all，最好拆分成多个union的子查询

#### 不做索引列转换操作

- 比如 avg之类的操作，将 String -> int ，这样会导致针对String 建立的索引失效
- 查出来做操作也行

#### 覆盖索引

- 尽量不要使用 select * ，使用多少就查询多少
- 如果查询索引全覆盖了，查询很快
- 如果某数据没有索引，先就查这个数据和索引，在通过索引查

#### join小表驱动大表

- 避免产生很多垃圾数据

### explain

- 效率依次下降
- 基本上所有查询都基本要在 range 以下
- 如果数据过千万，基本都要 eq_ref

![](image/Pasted%20image%2020241208025454.png)

### 性能指标

![](image/Pasted%20image%2020241208025856.png)

## 应用层性能优化

![](image/Pasted%20image%2020241208030154.png)

### 批量写

- 尽量第二种写法

![](image/Pasted%20image%2020241208030337.png)

#### 优势

![](image/Pasted%20image%2020241208030736.png)

![](image/Pasted%20image%2020241208030442.png)

## 连接配置优化

![](image/Pasted%20image%2020241208030913.png)

## 缓存配置优化

- 及时硬盘再快，也没有内存快，现在磁盘IO很难提升，但是内存便宜了

![](image/Pasted%20image%2020241208030933.png)

![](image/Pasted%20image%2020241208031242.png)

## 磁盘配置优化

![](image/Pasted%20image%2020241208031941.png)

## 事务提交优化

- 就像 java 中的 write 和 flush ，white 只是写到系统缓存，执行了 flush 才会写到磁盘
- 通常使用 2

![](image/Pasted%20image%2020241208032045.png)

## 读写分离

- 大部分都是读取操作
- 半同步只需要保证 slave 有一台接收到了最新的 binlog ，就完成事务提交，这样 master 挂了也能保证数据一致
- 这就需要运维人员的努力了，不是开发的范畴

![](image/Pasted%20image%2020241208204001.png)

![](image/Pasted%20image%2020241208204529.png)

![](image/Pasted%20image%2020241208205336.png)

### 主从延迟处理

![](image/Pasted%20image%2020241208221738.png)

# DDD

  ![](image/Pasted%20image%2020241208033722.png)

![](image/Pasted%20image%2020241208033736.png)

# 高事务要求

## 下单流程

![](image/Pasted%20image%2020241208035324.png)

## CAP and BASE

![](image/Pasted%20image%2020241208035443.png)

## 分布式事务

- 其实就是在 一致性 和 可用性 追究平衡，二阶段牺牲可用性
- 剩下的三个基本都是满足 BASE 理论

### 二阶段提交

- 一阶段 prepare
- 二阶段 commit
- 优势，一阶段并没有 commit，外部来看是看不到的，如果 for update 是会阻塞，这个是完全牺牲可用性
- 也就是数据库再执行这个，类似的操作是不行的，也就是牺牲了可用性
- 最快要等最慢，还要考虑网络丢包
- 一般都是使用数据库XA

![](image/Pasted%20image%2020241208040122.png)

### TCC

- 类似于二阶段提交，但是每个阶段就会执行 commit，外部可以读到，好处是不挑数据库
- 要准备 3 套 SQL 语句，对应 try、confirm、cancel
- 没有事务悬挂，外部可以读到暂时正确的数据，最后能最终一致

![](image/Pasted%20image%2020241208040926.png)

### 最大努力提交型

- 主要用于项目解耦
- 但是事务执行者 1 挂了，通常会导致数据丢失
- 这个方案主要用在数据可容忍丢失

![](image/Pasted%20image%2020241208041249.png)

### 事务型消息

- 最主要的就是有个反查操作，如果数据不一致就撤销操作

![](image/Pasted%20image%2020241208041508.png)

## Seata

- 数据库分布式就可以用

### 实现协议

![](image/Pasted%20image%2020241208042136.png)



## 下单流程

- 主要使用 TCC
- 最大努力就不能用，因为有资源竞争，最坏的情况 MQ 没收到库存扣光了

![](image/Pasted%20image%2020241208041939.png)

![](image/Pasted%20image%2020241208043123.png)

## 支付和取消流程

- 最大努力提交型
- 通常都要和第三方进行对账，线下修正，保证最终一致性
- 通常 MQ 和 HTTPS 都会不断地发送回调，直到确定，如果确认发送了中途丢失，还是会继续发送回调，于是需要接口的**幂等性**
- 支付成功后，及时回调也不会再次成功
- 一些重要的针对库存的操作基本都要实现幂等性
- 定时任务不需要那么精确，反正会重新查询
- 

![](image/Pasted%20image%2020241208044654.png)

![](image/Pasted%20image%2020241208045236.png)


# Redis

## 优劣势

![](image/Pasted%20image%2020241208170638.png)

## 数据结构

![](image/Pasted%20image%2020241208170954.png)

## 数据内存结构和线程模型

- 为什么使用多线程，主要是因为阻塞多
- 但是 redis 主要是内存操作，没有那么多需要阻塞，排队永远比多线程快，能够充分利用 cpu
- 如果内存可以完全隔离，多 cpu 运行不同的 redis 速度是会变快
- 但是在同一个机器，内存要加锁，单线程的优势就没了
- redis 并不是只有一个线程，只有工作线程是一个，网络 IO 和磁盘 IO 通常不止一个，因为有频繁阻塞场景 ，需要多线程充分利用 cpu

![](image/Pasted%20image%2020241208171152.png)

![](image/Pasted%20image%2020241208172606.png)

## 持久化

![](image/Pasted%20image%2020241208171232.png)

## 淘汰策略

- 如果是看做缓存，数据是允许淘汰，很多数据是数据库的备份
- 如果是在秒杀场景，可以把 redis 当做数据库

![](image/Pasted%20image%2020241208172649.png)

## 分布式策略

### 主从

- master 挂了， slave 不会自动切换

![](image/Pasted%20image%2020241208175451.png)

### 哨兵

- 引入了哨兵，就像微服务的注册中心

![](image/Pasted%20image%2020241208175540.png)

### 集群

- 4.0 后推出集群模式，node 节点互相关联，都知道对方的身份，通过竞选的方式产生全局身份
- 这个集群很难做机房隔离管理，一般都要求多地备份

![](image/Pasted%20image%2020241208180629.png)

### 分片部署

- 一致性哈希算法没出问题，加机器还是减机器都很无感
- 推荐这种方式

![](image/Pasted%20image%2020241208175826.png)

- 运维很麻烦

![](image/Pasted%20image%2020241208180730.png)

## 分布式锁

- 使用数据库实现分布式锁还是太重了，除非要求很高，一般都是使用reids实现

![](image/Pasted%20image%2020241208183722.png)

### setnx

- 又爱又恨，坑多
- 这个是原子化操作，也就是不会产生多线程下数据冲突的问题
- 有以下的坑
	1. 加锁了，忘记释放了（要加 expire），但是 setnx 和 expire 这两个操作不是原子性，也就是中间会执行其他语句，或者网络连接问题导致无法设置 expire，redis 开发者也想到了
		1. 我们可以书写 **lua 脚本**，这个是原子操作，只会同时成功和失败
		2. set key value ex 10 nx，官方提供的原子化操作语句
	2. 任务发生了以外，执行时间超过了设定时间，锁过期了，这个时候会产生问题，我们如何确保当前线程完成任务
		1. 也就是看门狗，会自动监听主线程是否完成，没完成自动延期
	3. 如果监听线程挂了，由于时间到期没有延期，锁被意外释放，这样会导致，分布式锁一个常见的问题，也就是不是锁的持有者将锁释放，client 1 释放了 client 2 的锁，这也是致命的。
		1. setnx 和 del lock 操作的对象必须是同一个 client 申请的，我们可以加入唯一标识，我们可以对 value 做文章，每次释放锁之前去查询 value 看是否是当前 client 申请的，如果不是就不释放，报错打日志或者撤销执行。
	4. redis 是易失性的，在集群环境 setnx 时候 master 挂了，通过 sentinel slave 切换成 master，slave 并没有同步之前在 master 上执行的 setnx
	5. 使用成熟的库，如 Redisson，而且还实现了红锁
### 总结

- 这种方式最好不要用在交易，要求强一致的场景，如果真正爆发问题是十分致命的，还会有安全隐患，如果要求很高还是使用数据库来实现分布式锁，这种方案是在业务上能够容忍可重入这个问题的场景

## 缓存弱点

- 其实都是一个问题，缓存不管用了，把数据库搞崩了
- 应对方案不同

### 穿透

- 客户端访问了一个不存在的 key，数据库也不存在这个数据，每次请求都落在 DB 上，请求量大了 DB 很容易打挂
- 商家下架了商品，用户却访问到了不存在的数据，数据库和 redis 都不存在这个数据，这是非恶意，业务逻辑允许
- 恶意的话，获取大量相关信息，每次都打在数据库上，查询 id 不存在的数据，DB 压力大
- 解决方案：设置一个不存在的标识位，把这个标识放到redis，这里标识不是null，而是空对象，一般要明确 null 的使用，别人接手或者自己搞忘了很容易留下坑，要使用特殊的标识来知道这个是空对象，int -1，String “”，json {}，object id=null，这样就能知道这个对象是我们设置的，缓存还是能抗住 ddos 攻击的
- 针对恶意的情况，我们还可以封禁 IP ，关小黑屋

### 击穿

- 数据库存在这条数据，同一时间大批量无法命中 redis 的请求打到了数据库上，导致数据库负载高
- 解决方案
	- 缓存预热（长 TTL）
	- 排队，把这个数据做成一把锁，访问 DB 的请求只有一个能进去，当缓存中有对应的值，再释放锁，有个问题就是这个请求挂掉了，这个解决方案也简单，我们就使用令牌，每次放几百个进去就行了

### 雪崩

- 很多时候数据库压力飙升，通常都是和 redis 批量热点数据过期有关
- 同一时间大批量的 redis key 失效，导致请求全部打到数据库
- 解决方案：错峰随机事件

# ElasticSearch

- 所有涉及到查询都可以用 ES

## 优劣势

![](image/Pasted%20image%2020241208223810.png)

## 倒排索引

### 分词

- 使用固定的分词手段获得一串有意义的且归一化的字符串
- 像英语里的 a 通常就会被忽略，像 apple、apples 会被提取为 appl 屏蔽掉一些无意义的信息

![](image/Pasted%20image%2020241208224645.png)

### 倒排索引

- 分析数据集对可分词数据进行分词，根据数据产生索引
- 对于 age 就无法分词，就是拿数据做索引，通常可以做宽表搜索

![](image/Pasted%20image%2020241208224818.png)

### 输入分析过程

![](image/Pasted%20image%2020241208235845.png)

### IK分词器对中文的支持

- 两种分词方式
	1. 词库
	2. smart word 最长匹配，不重复，用户通常用这来搜索
	3. max word 尽可能不丢失语义，只要遇到了关键词就可以找到
- 通常搜索使用 smart word，这样就避免很多无意义的搜索条目
- 建设索引要考虑尽可能全，而用户搜索要尽量精确，
- 还会有停用词 的 地 得
- 同义词 中国 中华
- 停用词和同义词对调优很有用

![](image/Pasted%20image%2020241209000339.png)

![](image/Pasted%20image%2020241209005331.png)

![](image/Pasted%20image%2020241209005359.png)
## 打分策略

### TF/IDF 打分

- 搜索出来结果，按什么排序，就是通过打分
- TF 对单条记录来说，这个分词出现的频率
- IDF 所有相关记录中这个分词出现频率的反比

![](image/Pasted%20image%2020241209002645.png)

## 分布式集群

- Raft 协议用来选举
- leader 是**控制节点**，不是数据节点，控制数据存储在哪台机器
- 因为能将索引数据分片，就像数据库的水平切分，所以查询能够并行且数据量小，最后做 union 操作
- 日志同步写，数据异步刷
- 深度分页，用游标解决
- 如果某个节点挂掉，leader通过选举，如果通过就踢出节点，将备份数据转正，然后建立新的分片备份
- es 请求可以访问任何活着的主机，都可以完成任务

![](image/Pasted%20image%2020241209003704.png)

![](image/Pasted%20image%2020241209004630.png)
## 语法

- 创建 test 索引 ，写在网址里，put 请求

![](image/Pasted%20image%2020241209005609.png)

- 添加数据

![](image/Pasted%20image%2020241209005723.png)

- 搜索

![](image/Pasted%20image%2020241209010029.png)

## 索引构建

- 全量索引就是写代码通过 java 代码导入
- 增量索引就是 canal，伪装成 mysql slave 读取增量 binlog 仿照消息中间件，将消息推送到 java 程序，注意记得只监听你需要建立索引的数据库。
- 一般来说，只需要一次全量，后面靠增量也行，但是数据量多了就是会有各种麻烦
- 实际会有各种问题，丢数据，应用挂掉了等等
- 最重大的问题是
	1. 因为全量备份和 canal 执行都是异步，如果同一个数据执行 2 次还好，数据冲突就是大问题，或者数据覆盖
	2. 塞入大量数据如何保证可用
- 通常解决就是两个 ES，一个备份，一个生产，而且塞入的数据塞入版本号，只能塞入新的，不能塞入旧的，这样就不会产生新数据被旧数据覆盖

![](image/Pasted%20image%2020241209011607.png)

# Neo4J

- 图数据库使用场景
	- 关注，粉丝
	- 好友
	- 多维度关系
	- 主要是找到用户关系精准推销
- 7474 WEB 界面 7687 接口
- 解决传统数据库一些痛点
- 使用去看文档，不复杂

![](image/Pasted%20image%2020241209014047.png)

![](image/Pasted%20image%2020241209014249.png)

## 分布式

- 考虑两个问题
	- 主从问题（Raft 协议，和 ES 很像）
	- 写入问题可以分片，典型是按边、点去做分片，一般使用边来做，（应用层实现）
	- 通常一台 core server + replication server 足够满足大流量了，数据太多就直接离线计算

![](image/Pasted%20image%2020241209022138.png)

# HBase

## Feed 流

![](image/Pasted%20image%2020241209022712.png)

### 实现难度

#### 数据量生产及关联查询问题

- 根据用户偏好，好友，行为，点赞，各种数据产生数据，我要查询查询的结果如何跟我个人定制

#### 时序性及个性化排序问题

- 天生排序性问题，用户也会定制排序

#### 深度分页问题

- 用户翻页太深，用户看来只需要20条，但是背后可能筛选了几万条，进行各种复杂操作

### 经典推拉模式

- 带有时序信息的瀑布流系统
- A 是 B 的粉丝
- 早期是推模式，但是忽略了大V几百万粉丝，这样写扩散很恐怖，第二个是僵尸用户，关注大V，产生空间浪费
- 现在使用推拉混合模式

![](image/Pasted%20image%2020241209060425.png)

![](image/Pasted%20image%2020241209060916.png)
## 优劣势

 
![](image/Pasted%20image%2020241209023816.png)

## 原理

![](image/Pasted%20image%2020241209024709.png)
![](image/Pasted%20image%2020241209024826.png)

## RowKey

- 整个数据库都是使用 rowkey 来建立的
- 引入了 scan，就像 Mysql 的全表扫描，HBase 没有二级索引，只能全表扫描
	- 这个情况可以将数据库异构掉，搜索我们可以使用 ES，但是这是脱裤子放屁，一般不会采用
	- 我们不太期待这个系统的实时性，**等吧**
	- 我们可以使用 startrow 和 stoprow 来限制查询，可以在元数据就知道文件在哪里，这样可以加速，所以 Hbase rowkey 要设计好

![](image/Pasted%20image%2020241209031524.png)

### 如何设计

- 需要散列，数字做 MD5
- 同样的请求路由策略集中，同一个用户请求尽量在一个同一个 Region Server 上，不会出现多个 Region 等待数据的情况，后面处理是请求在 HDFS 上并行化处理的，最后返回到 Region Server 上，集中处理还可以做缓存策略，性能更高
- 天生能有符合业务条件排序的能力，比如时间排序
- 没设计好，性能体验还不如不要用 HBase

# MongoDB

- 实现点赞评论
- 很像关系型数据库

## 优劣势

![](image/Pasted%20image%2020241210000822.png)

## 原理

- collection 可以保证原子性
- BJson，压缩

![](image/Pasted%20image%2020241210001242.png)

## 聚合脉冲

- 点赞很零碎，所以需要聚合请求

![](image/Pasted%20image%2020241210002930.png)

## 分布式

![](image/Pasted%20image%2020241210003201.png)